# Web Crawler with Flask

This is a web crawler application implemented with Python and Flask. It allows users to schedule URLs for crawling and retrieve the results, including the title, date, URL, and content of the crawled web pages.

## Table of Contents

- [Features](#features)
- [Getting Started](#getting-started)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation)
- [Usage](#usage)
  - [Scheduling URLs for Crawling](#scheduling-urls-for-crawling)
  - [Retrieving Crawl Results](#retrieving-crawl-results)
- [Examples](#examples)
- [Contributing](#contributing)
- [License](#license)

## Features

- Schedule multiple URLs for crawling without blocking incoming requests.
- Retrieve crawl results, including title, date, URL, and content.
- Handles concurrent crawling with multithreading.

## Getting Started

### Prerequisites

- Python 3
- Flask
- BeautifulSoup
- requests

### Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/kartikeynick/web-crawler.git

2. Change into the project directory:
    ```bash
   cd src
